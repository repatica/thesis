


%With this we conclude the dissertation. We will look back at the previous five chapters, summarize the main results and their consequences and discuss open problems for each of the topics.

We looked at two well-known and well-studied problems in phylogenetics, minimum hybridization (Chapters 2-5) and compatibility (Chapter 6). Even though both of these problems deal with combining phylogenetic trees into larger structures, they are of very different nature. First of all their inputs are different: minimum hybridization takes rooted trees while compatibility (the variant we studied) is a problem defined on unrooted trees. Furthermore, minimum hybridization requires all input trees to have an identical leaf label set, while for compatibility trees can have overlapping label sets. The outputs of these two problems are different too: minimum hybridization combines trees into a network (DAG), while compatibility looks for a supertree. The reason underlying this is that in the unrooted setting checking whether trees can be merged into a bigger tree is a hard problem, which was not the case when we considered rooted trees. 

This is why Chapter 6 is rather separate from the rest of the work done here. Our approach was to explore further the relationship between treewidth of a display graph and compatibility of the instance. This relationship has already been studied and it led to an efficient albeit nonconstructive algorithm for compatibility of unrooted trees. The motivation for our work was searching for a clean combinatorial algorithm for this problem. We wanted to know if incompatibility leaves some sort of a signal or a hint for us in the display graph; if presence (or absence) of certain structures can tell us something about weather partial trees all came from a same tree. And indeed we realized that absence of a $K_4$ minor in a display graph of any number of trees guarantees compatibility of that instance. We also gave a polynomial time algorithm to construct a supertree. A clean combinatorial algorithm that efficiently combines any number of unrooted trees into a supertree (if one exists) still remains an open question: our algorithm applies only to the case when the display graph has treewidth at most 2.

From the chapters that deal with minimum hybridization, the first three are very closely related. They were produced as a series of papers, each inspired by the previous one. We started with a theoretical result in Chapter 2: we showed that \mh is in APX if and only if \dfvs is in APX. This result also had an interesting consequence for the fixed parameter tractability of \mh. We saw that the inflation factor of 6 in the reduction from \dfvs to \mh was very closely linked to a reduction described by Bordewich and Semple~\cite{bordewich07b}. They showed that the input trees can be reduced to produce a weighted instance containing at most $14r$ taxa which we have sharpened to at most $9r$ taxa. Without this sharpening, the inflation factor we obtain would have been higher than 6. From this analysis it became clear that the kernel size has an important role to play in analyzing the approximability of \mh.

This raised some interesting general questions about the linkages between \mh and \dfvs. For example, the reduction by Bordewich and Semple, which gives a linear kernel for a weighted variant of \mh, can be modified slightly (as is e.g. done in~\cite{bonet10} for unrooted SPR distance) to obtain a quadratic kernel for \mh (without weights). This contrasts sharply with \dfvs. It is known that \dfvs is fixed parameter tractable~\cite{dfvsFPT}, but it is \emph{not} known whether \dfvs permits a polynomial-size kernel. Might \mh give us new insights into the structure of \dfvs (and vice-versa)? More generally: within which complexity frameworks is one of the two problems strictly harder than the other?





Another interesting consequence of this result is that approximating hybridization number by splitting it into \maf and \dfvs instances yields an extremely competitive practical algorithm. This is the topic of Chapters 3 (approximating hybridization number for two binary trees) and Chapter 4 (approximating hybridization number for two nonbinary trees). In both chapters we presented an algorithm and tested its performance. Our experiments with binary trees show that \textsc{Cycle Killer} is much faster than available exact methods once the input trees become sufficiently large and/or discordant. In over $96\%$ of the cases \textsc{Cycle Killer} finds the optimal solution and in the remaining cases it finds a solution very close to the optimum. We have shown that the most accurate mode of the program produces solutions that are at most a factor~2 from the optimum. In practice, the average-case approximation ratio of the most accurate mode that we observed was~1.003. The fastest mode of the algorithm on the other hand can be used on trees with thousands of leaves and provably constructs networks that are at most a factor of~4 from the optimum. The cycle-breaking technique also gives very good results when generalized to nonbinary trees. The algorithm is able to deal with very large instances that exact solvers will probably never be able to cope with. The practical worst-case approximation ratio observed in our experiments was 1.5 for the more accurate but slower mode of the algorithm and 4 for the faster but less accurate mode. Furthermore, in this chapter we have given improved FPT and polynomial-time approximation algorithms for nonbinary \maf.

%A number of interesting open problems remain. The best known polynomial-time approximation algorithms for both binary and nonbinary \maf have a factor of 3. While for nonbinary \maaf we have shown how to achieve an approximation factor of $d(c+3)$, but for binary the corresponding expression is $d(c+1)$. Might it be that the binary and nonbinary variants of \maaf are equally approximable, or is the nonbinary variant in some sense strictly more difficult to approximate? This gap remains something that needs to be further explored.

Our methods showed how, with a $d$-approximation for \dfvs and a $c$-approximation for \maf, we can obtain an approximation factor of $d(c+1)$ in the binary case and $d(c+3)$ in the nonbinary case. Might it be possible to also obtain $d(c+1)$ for the
nonbinary case, or is the nonbinary case somehow inherently less approximable using these techniques? Also, as we wrote in the original papers, approximation ratios of this form have the advantage that they automatically improve (both theoretically
and in practice) as techniques for solving \dfvs and \maf improve. Since publishing the original papers we have seen this happen. For example, for a long time the best approximation for \maf on two rooted binary trees was 3, recently a polynomial-time approximation ratio of 2.5 was given in \cite{conc3}. Even though we don't tackle unrooted \maf in this thesis, there has been recent progress on that front. In \cite{conc1} authors study \maf on both multiple rooted and multiple unrooted trees and give a polynomial-time approximation algorithm with approximation ratio 3 and 4 respectively. In the case of nonbinary trees, the first FPT algorithm and the first constant-ratio approximation for unrooted \maf are given in \cite{conc2}. 




Returning to hybridization number, an obvious next step is to try to build algorithms that can deal with multiple binary (and nonbinary) trees, which we presented in Chapter 5. However, this problem is relatively unexplored (at least when compared to the two tree case). When we are dealing with only two trees the standard approach to constructing a hybridization network is to puzzle it from the components of some AAF by wiring them appropriately. How this wiring should be done is completely determined by the AAF: each of the two hybridization edges above a component comes from a single tree. Furthermore, where these edges should be placed in the reconstruction of a network is also encoded in the AAF. In the case of more than two trees one must guess the wiring of the components. There is only a constant number of choices for wiring per component, so with $\Oh(k)$ components and guessing the wiring of them, we get an $\Oh(c^k \cdot \poly(n))$ time algorithm for reconstructing a hybridization network. 

The problem with this approach for multiple trees is the existence of what we called an invisible component: a set of nodes of the network that is not represented in the AAF. Unfortunately, even for the case of only three trees we found examples where every optimal network contained an invisible component. In this particular case, the three trees instances, we realized that although these nodes might be invisible in AAF, we can identify them in the input trees. This eventually let to our $\Oh(c^k \cdot \poly(n))$-time algorithm. Sadly enough, the framework of our algorithm extends to any number of trees, except in this key observation that invisible nodes can be seen in the input trees afterall. With already just four trees we found examples of ``truly invisible'' nodes, nodes not found in AAF or in any of the input trees. Guessing the number and structure of these components seems very challenging and remains open. 





% \cite{conc4}
% Fixed-Parameter and Approximation Algorithms for Maximum Agreement Forests of Multifurcating Trees
% 
% We present efficient fixed-parameter and approximation algorithms for the NP-hard problem of computing a maximum agreement forest (MAF) of a pair of multifurcating (nonbinary) rooted trees. Multifurcating trees arise naturally as a result of statistical uncertainty in current tree construction methods. The size of an MAF corresponds to the subtree prune-and-regraft distance of the two trees and is intimately connected to their hybridization number. These distance measures are essential tools for understanding reticulate evolution, such as lateral gene transfer, recombination, and hybridization. Our algorithms nearly match the running times of the currently best algorithms for the binary case. This is achieved using a combination of efficient branching rules (similar to but more complex than in the binary case) and a novel edge protection scheme that further reduces the size of the search space the algorithms need to explore.
% 
% 








